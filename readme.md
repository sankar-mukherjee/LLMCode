
## LLMCode

My LLM learnings

## Contents

- llm basic
- llm optimization
    - flash attention (pytorch in-built)
    - kv cache
    - weight tying
    - FFN modification (GELU -> SwiGLU)
    - RMSNorm
    - QKNorm
    - RoPE (Rotary Positional Embeddings)
- qunatization aware training (4bit, 8bit)
    - QAT
    - quantization types
        - per tensor qunatization
        - per channel qunatization

