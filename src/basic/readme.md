# `src/basic`

Small, focused learning modules for core neural network concepts.

## Python modules

- `train_0.py`: minimal training loop scaffold.
- `custom_nn_module.py`: custom `nn.Module` patterns and usage.
- `activations.py`: activation function experiments.
- `batchNorm.py`: batch normalization behavior and implementation notes.
- `dropout.py`: dropout behavior in training/inference.
- `lora_layer.py`: simple LoRA-style low-rank adaptation layer.
- `straight_through_estimator.py`: STE-based gradient flow example for quantization-style ops.

## Linear algebra

- `linear_algebra/code_examples.py`: linear algebra code examples for ML basics.

## ML notes

- `ml/activations.py`: activation-function-focused ML notes and code examples.

![Activation Equations](ml/activation_eq.png)

## CNN

- `cnn/cnn.py`: basic convolutional neural network example.

![CNN](cnn/cnn.jpg)

## RNN family

- `rnn/rnn.py`: RNN/LSTM/GRU examples and comparisons.

![RNN](rnn/rnn.webp)
![GRU](rnn/gru.png)
![LSTM](rnn/lstm.png)

## Loss

- `loss/loss.py`: loss function demonstrations.

![Loss Equation](loss/loss_eq.png)
